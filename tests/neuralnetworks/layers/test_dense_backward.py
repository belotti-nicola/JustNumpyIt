import pytest
import numpy as np

from src.neuralnetworks.layers.denselayer import DenseL

A = np.array([[-1,  2,  1,  1],
              [ 2, -2, -1, -3],
              [ 3, -3,  2,  2]],
              np.double).reshape(3,4)
b = np.array([1,2,-3],np.double).reshape(3,1)

testdata = [
    ([1, 1,-3, 2],
     [0.09355771143,     .012464,     -0.0021],
     [[0.09355771143,	0.09355771143,	-0.2806731343,	0.1871154229],
      [0.01246474473,	0.01246474473,	-0.03739423418,	0.02492948946],
      [-0.002169039786,	-0.002169039786,	0.006507119357,	-0.004338079572]],
     [0.09355771143, 0.01246474473, -0.002169039786]
    ),

    ([2, 2, 3, 1],
     [0.09248537426, -0.00001471016005, 0.01251519887],
     [[0.1849707485,	0.1849707485,	0.2774561228,	0.09248537426],
      [-0.0000294203201, -0.0000294203201,	-0.00004413048015,	-0.00001471016005],
      [0.02503039774,	0.02503039774,	0.03754559661,	0.01251519887]
      ],
     [0.09248537426, -0.00001471016005, 0.01251519887]
     ),



    ([1,1, -3,-1],
     [0.000000002060872896, 0.00004539934813, -0.000000005602541988],
     [[0.000000002060872896, 0.000000002060872896,	-0.000000006182618688,	-0.000000002060872896],
      [0.00004539934813,	0.00004539934813,	-0.0001361980444,	-0.00004539934813],
      [-0.000000005602541988,	-0.000000005602541988,	0.00000001680762597,	0.000000005602541988]
      ],
      [0.000000002060872896, 0.00004539934813, -0.000000005602541988]
    ),
    
    
    ([3, -6,2,-1],
     [0, 0.00004449445223, 0.006603562219],
     [[0,	0,	0,	0],
      [0.0001334833567,	-0.0002669667134,	0.00008898890447,	-0.00004449445223],
      [0.01981068666,	-0.03962137331,	0.01320712444,	-0.006603562219]
      ],
     [0, 0.00004449445223, 0.006603562219]
    )
]


@pytest.mark.parametrize("inp,output_gradient,dA,db",testdata)
def test_backward(inp,output_gradient,dA,db):
    L = DenseL(4,3)
    L.setA(A)
    L.setb(b)
    x = np.array(inp,np.double).reshape(4,1)
    grad_y = np.array(output_gradient,np.double).reshape(3,1)

    L.forward(x)
    input_gradient = L.backward(grad_y)
    

    assert L.db.shape == L.b.shape
    assert L.dA.shape == L.A.shape

    assert L.dA[0][0] - dA[0][0] < .001
    assert L.dA[0][1] - dA[0][1] < .001
    assert L.dA[0][2] - dA[0][2] < .001
    assert L.dA[0][3] - dA[0][3] < .001
    assert L.dA[1][0] - dA[1][0] < .001
    assert L.dA[1][1] - dA[1][1] < .001
    assert L.dA[1][2] - dA[1][2] < .001
    assert L.dA[1][3] - dA[1][3] < .001
    assert L.dA[2][0] - dA[2][0] < .001
    assert L.dA[2][1] - dA[2][1] < .001
    assert L.dA[2][2] - dA[2][2] < .001
    assert L.dA[2][3] - dA[2][3] < .001

    assert L.db[0] - db[0] < .001
    assert L.db[1] - db[1] < .001
    assert L.db[2] - db[2] < .001


    assert np.linalg.norm(input_gradient - np.dot(L.A.T,grad_y)) < .001

  



    
    
